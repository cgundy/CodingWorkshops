{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to pandas and sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommendation System\n",
    "We live in a world surrounded by recommendation systems - our shopping habbits, our reading habits, political opinions are heavily influenced by recommendation algorithms. So lets take a closer look at how to build a basic recommendation system.\n",
    "\n",
    "Simply put a recommendation system learns from your previous behavior and tries to recommend items that are similar to your previous choices. While there are a multitude of approaches for building recommendation systems, we will take a simple approach that is easy to understand and has a reasonable performance.\n",
    "\n",
    "For this exercise we will build a recommendation system that predicts which talks you'll enjoy at a conference - specifically our favorite conference Pycon!\n",
    "\n",
    "### Before you proceed\n",
    "This project is still in alpha stage. Bugs, typos, spelling, grammar, terminologies - there's every scope of finding bugs. If you have found one - [open an issue on github](https://github.com/chicagopython/CodingWorkshops/issues/new). Pull Requests with corrections, fixes and enhancements will be received with open arms! Don't forget to add yourself to the [list of contributors to this project](https://github.com/chicagopython/CodingWorkshops/blob/master/README.md). \n",
    "\n",
    "\n",
    "#### Recommendation for Pycon talks\n",
    "Take a look at 2018 [schedule](https://us.pycon.org/2018/schedule/).\n",
    "With 32 tuotorials, 12 sponsor workshops, 16 talks at the education summit, and 95 talks at the main conference - Pycon has a lot to offer. Reading through all the talk descriptions and filtering out the ones that you should go to is a tedious process. \n",
    "Lets build a recommendation system that recommends talks from Pycon 2018, based on the ones that a person went to in 2017. This way the attendee does not waste any time deciding which talk to go to and spend more time making friends on the hallway track! \n",
    "\n",
    "We will be using [`pandas`](https://pandas.pydata.org/) and [`scikit-learn`](http://scikit-learn.org/) to build the recommnedation system using the text description of talks.\n",
    "\n",
    "\n",
    "\n",
    "### Definitions\n",
    "#### Documents\n",
    "In our example the talk descriptions make up the documents\n",
    "#### Class\n",
    "We have two classes to classify our documents\n",
    "- The talks that the attendee would like to see \"in person\". Denoted by 1\n",
    "- The talks that the attendee would watch \"later online\". Denoted by 0\n",
    "\n",
    "A talk description is labeled 0 would mean the user has chosen to watch it later and a label 1 would mean the user has chose to watch it in person.\n",
    "\n",
    "### Supervised Learning\n",
    "In Supervised learning we inspect each observation in a given dataset and manually label them. These manually labeled data is used to construct a model that can predict the labels on new data. We will use a Supervised Learning technique called Support Vector Machines.\n",
    "\n",
    "In unsupervised learning we do not need any manual labeling. The recommendation system finds the pattern in the data to build a model that can be used for recommendation.\n",
    "\n",
    "### Dataset\n",
    "The dataset contains the talk description and speaker details from Pycon 2017 and 2018. All the 2017 talk data has been labeled by a user who has been to Pycon 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required packages installation\n",
    "The following packages are needed for this project. Execute the cell below to install them. \n",
    "\n",
    "    numpy==1.14.2\n",
    "    pandas==0.22.0\n",
    "    python-dateutil==2.7.2\n",
    "    pytz==2018.4\n",
    "    scikit-learn==0.19.1\n",
    "    scipy==1.0.1\n",
    "    six==1.11.0\n",
    "    sklearn==0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Flask in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (1.0.2)\n",
      "Collecting Flask_RESTful (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/17/44/6e490150ee443ca81d5f88b61bb4bbb133d44d75b0b716ebe92489508da4/Flask_RESTful-0.3.7-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (1.15.1)\n",
      "Requirement already satisfied: pandas in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (0.23.4)\n",
      "Requirement already satisfied: python-dateutil in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (2.7.3)\n",
      "Requirement already satisfied: pytz in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (2018.5)\n",
      "Requirement already satisfied: scikit-learn in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.19.2)\n",
      "Requirement already satisfied: scipy in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (1.1.0)\n",
      "Requirement already satisfied: six in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (1.11.0)\n",
      "Collecting sklearn (from -r requirements.txt (line 10))\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: jupyter in /anaconda3/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (1.0.0)\n",
      "Collecting altair (from -r requirements.txt (line 12))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/24/3e50e226a79db1bb1427bf8c58cc4dc7c2f74c39b728af005f4b11d1760c/altair-3.2.0-py2.py3-none-any.whl (596kB)\n",
      "\u001b[K    100% |████████████████████████████████| 604kB 2.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting vega (from -r requirements.txt (line 13))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/1c/6c7b9f541484dfd46ce69bed361b2cac6064465fadf5bd39b651f0b1658e/vega-2.5.0-py3-none-any.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 5.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: Werkzeug>=0.14 in /anaconda3/lib/python3.7/site-packages (from Flask->-r requirements.txt (line 1)) (0.14.1)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /anaconda3/lib/python3.7/site-packages (from Flask->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: click>=5.1 in /anaconda3/lib/python3.7/site-packages (from Flask->-r requirements.txt (line 1)) (6.7)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /anaconda3/lib/python3.7/site-packages (from Flask->-r requirements.txt (line 1)) (0.24)\n",
      "Collecting aniso8601>=0.82 (from Flask_RESTful->-r requirements.txt (line 2))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/a4/b4fcadbdab46c2ec2d2f6f8b4ab3f64fd0040789ac7f065eba82119cd602/aniso8601-7.0.0-py2.py3-none-any.whl (42kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 17.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: notebook in /anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 11)) (5.6.0)\n",
      "Requirement already satisfied: qtconsole in /anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 11)) (4.4.1)\n",
      "Requirement already satisfied: ipywidgets in /anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 11)) (7.4.1)\n",
      "Requirement already satisfied: jupyter-console in /anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 11)) (5.2.0)\n",
      "Requirement already satisfied: nbconvert in /anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 11)) (5.4.0)\n",
      "Requirement already satisfied: ipykernel in /anaconda3/lib/python3.7/site-packages (from jupyter->-r requirements.txt (line 11)) (4.9.0)\n",
      "Requirement already satisfied: jsonschema in /anaconda3/lib/python3.7/site-packages (from altair->-r requirements.txt (line 12)) (2.6.0)\n",
      "Requirement already satisfied: entrypoints in /anaconda3/lib/python3.7/site-packages (from altair->-r requirements.txt (line 12)) (0.2.3)\n",
      "Requirement already satisfied: toolz in /anaconda3/lib/python3.7/site-packages (from altair->-r requirements.txt (line 12)) (0.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda3/lib/python3.7/site-packages (from Jinja2>=2.10->Flask->-r requirements.txt (line 1)) (1.0)\n",
      "Requirement already satisfied: prometheus-client in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.3.1)\n",
      "Requirement already satisfied: jupyter-client>=5.2.0 in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (5.2.3)\n",
      "Requirement already satisfied: Send2Trash in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (1.5.0)\n",
      "Requirement already satisfied: nbformat in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (4.4.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (17.1.2)\n",
      "Requirement already satisfied: traitlets>=4.2.1 in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (4.3.2)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (4.4.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.8.1)\n",
      "Requirement already satisfied: tornado>=4 in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (5.1)\n",
      "Requirement already satisfied: ipython-genutils in /anaconda3/lib/python3.7/site-packages (from notebook->jupyter->-r requirements.txt (line 11)) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 11)) (3.4.1)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /anaconda3/lib/python3.7/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 11)) (6.5.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 11)) (1.0.15)\n",
      "Requirement already satisfied: pygments in /anaconda3/lib/python3.7/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 11)) (2.2.0)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.8.3)\n",
      "Requirement already satisfied: bleach in /anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (2.1.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (1.4.2)\n",
      "Requirement already satisfied: testpath in /anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.3.1)\n",
      "Requirement already satisfied: defusedxml in /anaconda3/lib/python3.7/site-packages (from nbconvert->jupyter->-r requirements.txt (line 11)) (0.5.0)\n",
      "Requirement already satisfied: decorator in /anaconda3/lib/python3.7/site-packages (from traitlets>=4.2.1->notebook->jupyter->-r requirements.txt (line 11)) (4.3.0)\n",
      "Requirement already satisfied: pickleshare in /anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (0.7.4)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (4.6.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (0.12.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (40.2.0)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (0.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (0.8.1)\n",
      "Requirement already satisfied: backcall in /anaconda3/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (0.1.0)\n",
      "Requirement already satisfied: wcwidth in /anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->-r requirements.txt (line 11)) (0.1.7)\n",
      "Requirement already satisfied: html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre in /anaconda3/lib/python3.7/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 11)) (1.0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptyprocess>=0.5 in /anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0->ipywidgets->jupyter->-r requirements.txt (line 11)) (0.3.1)\n",
      "Requirement already satisfied: webencodings in /anaconda3/lib/python3.7/site-packages (from html5lib!=1.0b1,!=1.0b2,!=1.0b3,!=1.0b4,!=1.0b5,!=1.0b6,!=1.0b7,!=1.0b8,>=0.99999999pre->bleach->nbconvert->jupyter->-r requirements.txt (line 11)) (0.5.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/cgundy/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "\u001b[31mtwisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.\u001b[0m\n",
      "Installing collected packages: aniso8601, Flask-RESTful, sklearn, altair, vega\n",
      "Successfully installed Flask-RESTful-0.3.7 altair-3.2.0 aniso8601-7.0.0 sklearn-0.0 vega-2.5.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise A: Load the data\n",
    "The data directory contains the snapshot of one such user's labeling - lets load that up and start with our analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>presenters</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>location</th>\n",
       "      <th>talk_dt</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5 ways to deploy your Python web app in 2017</td>\n",
       "      <td>You’ve built a fine Python web application and...</td>\n",
       "      <td>Andrew T. Baker</td>\n",
       "      <td>2018-04-19 00:59:20.151875</td>\n",
       "      <td>2018-04-19 00:59:20.151875</td>\n",
       "      <td>Portland Ballroom 252–253</td>\n",
       "      <td>2017-05-08 15:15:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A gentle introduction to deep learning with Te...</td>\n",
       "      <td>Deep learning's explosion of spectacular resul...</td>\n",
       "      <td>Michelle Fullwood</td>\n",
       "      <td>2018-04-19 00:59:20.158338</td>\n",
       "      <td>2018-04-19 00:59:20.158338</td>\n",
       "      <td>Oregon Ballroom 203–204</td>\n",
       "      <td>2017-05-08 16:15:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aiosmtpd - A better asyncio based SMTP server</td>\n",
       "      <td>smtpd.py has been in the standard library for ...</td>\n",
       "      <td>Barry Warsaw</td>\n",
       "      <td>2018-04-19 00:59:20.161866</td>\n",
       "      <td>2018-04-19 00:59:20.161866</td>\n",
       "      <td>Oregon Ballroom 203–204</td>\n",
       "      <td>2017-05-08 14:30:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Algorithmic Music Generation</td>\n",
       "      <td>Music is mainly an artistic act of inspired cr...</td>\n",
       "      <td>Padmaja V Bhagwat</td>\n",
       "      <td>2018-04-19 00:59:20.165526</td>\n",
       "      <td>2018-04-19 00:59:20.165526</td>\n",
       "      <td>Portland Ballroom 251 &amp; 258</td>\n",
       "      <td>2017-05-08 17:10:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>An Introduction to Reinforcement Learning</td>\n",
       "      <td>Reinforcement learning (RL) is a subfield of m...</td>\n",
       "      <td>Jessica Forde</td>\n",
       "      <td>2018-04-19 00:59:20.169075</td>\n",
       "      <td>2018-04-19 00:59:20.169075</td>\n",
       "      <td>Portland Ballroom 252–253</td>\n",
       "      <td>2017-05-08 13:40:00.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   1       5 ways to deploy your Python web app in 2017   \n",
       "1   2  A gentle introduction to deep learning with Te...   \n",
       "2   3      aiosmtpd - A better asyncio based SMTP server   \n",
       "3   4                       Algorithmic Music Generation   \n",
       "4   5          An Introduction to Reinforcement Learning   \n",
       "\n",
       "                                         description         presenters  \\\n",
       "0  You’ve built a fine Python web application and...    Andrew T. Baker   \n",
       "1  Deep learning's explosion of spectacular resul...  Michelle Fullwood   \n",
       "2  smtpd.py has been in the standard library for ...       Barry Warsaw   \n",
       "3  Music is mainly an artistic act of inspired cr...  Padmaja V Bhagwat   \n",
       "4  Reinforcement learning (RL) is a subfield of m...      Jessica Forde   \n",
       "\n",
       "                 date_created               date_modified  \\\n",
       "0  2018-04-19 00:59:20.151875  2018-04-19 00:59:20.151875   \n",
       "1  2018-04-19 00:59:20.158338  2018-04-19 00:59:20.158338   \n",
       "2  2018-04-19 00:59:20.161866  2018-04-19 00:59:20.161866   \n",
       "3  2018-04-19 00:59:20.165526  2018-04-19 00:59:20.165526   \n",
       "4  2018-04-19 00:59:20.169075  2018-04-19 00:59:20.169075   \n",
       "\n",
       "                      location                     talk_dt  year  label  \n",
       "0    Portland Ballroom 252–253  2017-05-08 15:15:00.000000  2017    0.0  \n",
       "1      Oregon Ballroom 203–204  2017-05-08 16:15:00.000000  2017    0.0  \n",
       "2      Oregon Ballroom 203–204  2017-05-08 14:30:00.000000  2017    1.0  \n",
       "3  Portland Ballroom 251 & 258  2017-05-08 17:10:00.000000  2017    0.0  \n",
       "4    Portland Ballroom 252–253  2017-05-08 13:40:00.000000  2017    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df=pd.read_csv('talks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a brief description of the interesting fields.\n",
    "\n",
    "variable | description  \n",
    "------|------|\n",
    "`title`|Title of the talk\n",
    "`description`|Description of the talk\n",
    "`year`|Is it a `2017` talk or `2018`  \n",
    "`label`|`1` indicates the user preferred seeing the talk in person,<br> `0` indicates they would schedule it for later.\n",
    "\n",
    "Note all 2018 talks are set to 1. However they are only placeholders, and are not used in training the model. We will  use 2017 data for training, and predict the labels on the 2018 talks.\n",
    "\n",
    "Lets start by selecting the 2017 talk descriptions that were labeled by the user for watching in person.\n",
    "\n",
    "```python\n",
    "df[(df.year==2017) & (df.label==1)]['description']\n",
    "```\n",
    "\n",
    "Print the description of the talks that the user preferred watching in person. How many such talks are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Exploring the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Select 2017 talk description and labels from the Pandas dataframe. How many of them are present? Do the same for 2018 talks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You’ve built a fine Python web application and...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deep learning's explosion of spectacular resul...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smtpd.py has been in the standard library for ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music is mainly an artistic act of inspired cr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reinforcement learning (RL) is a subfield of m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  label\n",
       "0  You’ve built a fine Python web application and...    0.0\n",
       "1  Deep learning's explosion of spectacular resul...    0.0\n",
       "2  smtpd.py has been in the standard library for ...    1.0\n",
       "3  Music is mainly an artistic act of inspired cr...    0.0\n",
       "4  Reinforcement learning (RL) is a subfield of m...    0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_2017 = df[df['year']==2017][['description','label']]\n",
    "desc_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "description    95\n",
       "label           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_2017.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2017 talks will be used for training and the 2018 talks will we used for predicting. Set the values of `year_labeled` and `year_predict` to appropriate values and print out the values of `description_labeled` and `description_predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_labeled=2017\n",
    "year_predict=2018\n",
    " = df[df.year==year_labeled]['description']\n",
    "description_predict = df[df.year==year_predict]['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Introduction to Text Analysis\n",
    "![text-analysis](text-analysis.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a quick overview of text analysis. Our end goal is to train a machine learning algorithm by making it go through enough documents from each class to recognize the distingusihing characteristics in documents from a particular class. \n",
    "\n",
    "1. *Labeling* - This is the step where the user (i.e. a human) reviews a set of documents and manually classifies them. For our problem, here a Pycon attendee is labeling a talk description from 2017 as \"watch later\"(0) or \"watch now\" (1).\n",
    "1. *Training/Testing split* - In order to test our algorithm, we split parts of our labeled data into training (used to train the algorithm) and testing set (used to test the algorithm).\n",
    "1. *Vectorization & feature extraction* - Since machine learning algorithms deal with numbers rather than words, we vectorize our documents - i.e. we split the documents into individual unique words and count the frequency of their occurance across documents. There are different data normalization is possible at this stage like stop words removal, [lemmatization](https://spacy.io/api/lemmatizer) - but we will skip them for now. Each individual token occurrence frequency (normalized or not) is treated as a feature.\n",
    "1. *Model training* - This is where we build the model.\n",
    "1. *Model testing* - Here we test out the model to see how it is performing against label data as we subject it to the previously set aside test set.\n",
    "1. *Tweak and train* - If our measures are not satisfactory, we will change the parameters that define different aspects of the machine learning algorithm and we will train the model again.\n",
    "1. Once satisfied with the results from the previous step, we are now ready to deploy the model and have new unlabled documents be classified by it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Vectorize and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we build the feature set by tokenization, counting and normalization of the bi-grams from the text descriptions of the talk.\n",
    "\n",
    "**tokenizing** strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators\n",
    "\n",
    "**counting** the occurrences of tokens in each document\n",
    "\n",
    "**normalizing** and weighting with diminishing importance tokens that occur in the majority of samples / documents\n",
    "\n",
    "You can find more information on text feature extraction [here](http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction) and TfidfVectorizer [here](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra Credit\n",
    "Note that we are choosing default value on all parameters for `TfidfVectorizer`. While this is a starting point, for better results we would want to come back and tune them to reduce noise. You can try that after you have taken a first pass through all the exercises. You might consider using [spacy](https://spacy.io/api/lemmatizer) to fine tune the input to `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1 Fit_transform\n",
    "We will use the [fit_transform](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform) method to learn the vocabulary dictionary and return term-document matrix. What should be the input to `fit_transform`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_text_labeled = vectorizer.fit_transform(description_labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2 Inspect the vocabulary\n",
    "Take a look at the vocabulary dictionary that is accessible by calling `vocabulary_` on the `vectorizer`. The stopwords can be accessed using `stop_words_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ve': 7848,\n",
       " 'built': 904,\n",
       " 'fine': 2768,\n",
       " 'python': 5666,\n",
       " 'web': 7992,\n",
       " 'application': 357,\n",
       " 'ready': 5894,\n",
       " 'share': 6493,\n",
       " 'world': 8133,\n",
       " 'best': 751,\n",
       " 'way': 7958,\n",
       " 'deploy': 1862,\n",
       " 'app': 347,\n",
       " '2017': 25,\n",
       " 'talk': 7025,\n",
       " 'demonstrate': 1837,\n",
       " 'popular': 5305,\n",
       " 'techniques': 7134,\n",
       " 'deploying': 1864,\n",
       " 'applications': 380,\n",
       " 'll': 4143,\n",
       " 'start': 6770,\n",
       " 'simple': 6532,\n",
       " 'flask': 2794,\n",
       " 'expose': 2599,\n",
       " 'times': 7341,\n",
       " 'learn': 3901,\n",
       " 'use': 7651,\n",
       " 'different': 1991,\n",
       " 'tools': 7394,\n",
       " 'services': 6462,\n",
       " 'available': 591,\n",
       " 'modern': 4623,\n",
       " 'developer': 1918,\n",
       " 'specific': 6696,\n",
       " 'topics': 7420,\n",
       " 'covered': 1576,\n",
       " 'include': 3463,\n",
       " 'exposing': 2607,\n",
       " 'local': 4200,\n",
       " 'dev': 1913,\n",
       " 'environment': 2407,\n",
       " 'ngrok': 4818,\n",
       " 'using': 7754,\n",
       " 'platform': 5262,\n",
       " 'service': 6455,\n",
       " 'paas': 5043,\n",
       " 'like': 4065,\n",
       " 'heroku': 3271,\n",
       " 'going': 3048,\n",
       " 'serverless': 6444,\n",
       " 'aws': 630,\n",
       " 'lambda': 3815,\n",
       " 'configuring': 1437,\n",
       " 'vm': 7912,\n",
       " 'google': 3078,\n",
       " 'compute': 1386,\n",
       " 'engine': 2368,\n",
       " 'thinking': 7282,\n",
       " 'inside': 3547,\n",
       " 'box': 820,\n",
       " 'docker': 2125,\n",
       " 'briefly': 835,\n",
       " 'touch': 7426,\n",
       " 'pros': 5588,\n",
       " 'cons': 1445,\n",
       " 'technique': 7131,\n",
       " 'help': 3240,\n",
       " 'figure': 2740,\n",
       " 'right': 6162,\n",
       " 'end': 2349,\n",
       " 'basic': 673,\n",
       " 'understanding': 7590,\n",
       " 'work': 8080,\n",
       " 'try': 7511,\n",
       " 've built': 7850,\n",
       " 'built fine': 909,\n",
       " 'fine python': 2770,\n",
       " 'python web': 5793,\n",
       " 'web application': 7995,\n",
       " 'application ready': 371,\n",
       " 'ready share': 5896,\n",
       " 'share world': 6498,\n",
       " 'world best': 8135,\n",
       " 'best way': 762,\n",
       " 'way deploy': 7960,\n",
       " 'deploy app': 1863,\n",
       " 'app 2017': 348,\n",
       " '2017 talk': 27,\n",
       " 'talk demonstrate': 7041,\n",
       " 'demonstrate popular': 1843,\n",
       " 'popular techniques': 5307,\n",
       " 'techniques deploying': 7136,\n",
       " 'deploying python': 1865,\n",
       " 'web applications': 7996,\n",
       " 'applications ll': 387,\n",
       " 'll start': 4182,\n",
       " 'start simple': 6774,\n",
       " 'simple flask': 6537,\n",
       " 'flask application': 2795,\n",
       " 'application expose': 365,\n",
       " 'expose world': 2602,\n",
       " 'world times': 8146,\n",
       " 'times learn': 7344,\n",
       " 'learn use': 3925,\n",
       " 'use different': 7662,\n",
       " 'different tools': 2007,\n",
       " 'tools services': 7413,\n",
       " 'services available': 6463,\n",
       " 'available modern': 596,\n",
       " 'modern python': 4632,\n",
       " 'python developer': 5694,\n",
       " 'developer specific': 1925,\n",
       " 'specific topics': 6702,\n",
       " 'topics covered': 7422,\n",
       " 'covered include': 1578,\n",
       " 'include exposing': 3464,\n",
       " 'exposing local': 2608,\n",
       " 'local dev': 4201,\n",
       " 'dev environment': 1914,\n",
       " 'environment ngrok': 2409,\n",
       " 'ngrok using': 4819,\n",
       " 'using platform': 7775,\n",
       " 'platform service': 5269,\n",
       " 'service paas': 6459,\n",
       " 'paas like': 5044,\n",
       " 'like heroku': 4078,\n",
       " 'heroku going': 3272,\n",
       " 'going serverless': 3054,\n",
       " 'serverless aws': 6446,\n",
       " 'aws lambda': 632,\n",
       " 'lambda configuring': 3816,\n",
       " 'configuring vm': 1438,\n",
       " 'vm google': 7913,\n",
       " 'google compute': 3079,\n",
       " 'compute engine': 1388,\n",
       " 'engine thinking': 2370,\n",
       " 'thinking inside': 7283,\n",
       " 'inside box': 3548,\n",
       " 'box using': 826,\n",
       " 'using docker': 7761,\n",
       " 'docker ll': 2127,\n",
       " 'll briefly': 4145,\n",
       " 'briefly touch': 836,\n",
       " 'touch pros': 7430,\n",
       " 'pros cons': 5589,\n",
       " 'cons technique': 1446,\n",
       " 'technique help': 7132,\n",
       " 'help figure': 3248,\n",
       " 'figure right': 2742,\n",
       " 'right app': 6163,\n",
       " 'app end': 350,\n",
       " 'end talk': 2358,\n",
       " 'talk basic': 7031,\n",
       " 'basic understanding': 681,\n",
       " 'understanding techniques': 7598,\n",
       " 'techniques work': 7143,\n",
       " 'work ll': 8093,\n",
       " 'll ready': 4178,\n",
       " 'ready try': 5898,\n",
       " 'deep': 1805,\n",
       " 'learning': 3931,\n",
       " 'explosion': 2595,\n",
       " 'spectacular': 6710,\n",
       " 'results': 6116,\n",
       " 'past': 5132,\n",
       " 'years': 8228,\n",
       " 'make': 4318,\n",
       " 'appear': 355,\n",
       " 'esoteric': 2426,\n",
       " 'daunting': 1750,\n",
       " 'reality': 5908,\n",
       " 'familiar': 2667,\n",
       " 'traditional': 7455,\n",
       " 'machine': 4269,\n",
       " 'exploring': 2592,\n",
       " 'aims': 191,\n",
       " 'gently': 3004,\n",
       " 'bridge': 829,\n",
       " 'divide': 2114,\n",
       " 'demonstrating': 1848,\n",
       " 'operates': 4954,\n",
       " 'core': 1525,\n",
       " 'concepts': 1407,\n",
       " 'getting': 3013,\n",
       " 'attendees': 526,\n",
       " 'started': 6777,\n",
       " 'coding': 1205,\n",
       " 'neural': 4784,\n",
       " 'networks': 4780,\n",
       " 'tensorflow': 7171,\n",
       " 'library': 4029,\n",
       " 'deep learning': 1808,\n",
       " 'learning explosion': 3939,\n",
       " 'explosion spectacular': 2596,\n",
       " 'spectacular results': 6711,\n",
       " 'results past': 6119,\n",
       " 'past years': 5134,\n",
       " 'years make': 8233,\n",
       " 'make appear': 4319,\n",
       " 'appear esoteric': 356,\n",
       " 'esoteric daunting': 2427,\n",
       " 'daunting reality': 1751,\n",
       " 'reality familiar': 5909,\n",
       " 'familiar traditional': 2669,\n",
       " 'traditional machine': 7456,\n",
       " 'machine learning': 4274,\n",
       " 'learning ready': 3949,\n",
       " 'ready start': 5897,\n",
       " 'start exploring': 6772,\n",
       " 'exploring deep': 2593,\n",
       " 'learning talk': 3951,\n",
       " 'talk aims': 7027,\n",
       " 'aims gently': 195,\n",
       " 'gently bridge': 3005,\n",
       " 'bridge divide': 830,\n",
       " 'divide demonstrating': 2115,\n",
       " 'demonstrating deep': 1849,\n",
       " 'learning operates': 3947,\n",
       " 'operates core': 4955,\n",
       " 'core machine': 1528,\n",
       " 'learning concepts': 3935,\n",
       " 'concepts getting': 1409,\n",
       " 'getting attendees': 3014,\n",
       " 'attendees started': 528,\n",
       " 'started coding': 6778,\n",
       " 'coding deep': 1206,\n",
       " 'deep neural': 1809,\n",
       " 'neural networks': 4786,\n",
       " 'networks using': 4783,\n",
       " 'using google': 7765,\n",
       " 'google tensorflow': 3080,\n",
       " 'tensorflow library': 7172,\n",
       " 'smtpd': 6613,\n",
       " 'py': 5637,\n",
       " 'standard': 6754,\n",
       " 'common': 1259,\n",
       " 'tool': 7377,\n",
       " 'smtp': 6611,\n",
       " 'lmtp': 4190,\n",
       " 'servers': 6448,\n",
       " 'handle': 3172,\n",
       " 'email': 2312,\n",
       " 'based': 663,\n",
       " 'communication': 1274,\n",
       " 'providing': 5619,\n",
       " 'protocol': 5590,\n",
       " 'implementations': 3419,\n",
       " 'fundamental': 2946,\n",
       " 'module': 4642,\n",
       " 'higher': 3280,\n",
       " 'level': 3985,\n",
       " 'lazr': 3886,\n",
       " 'smtptest': 6615,\n",
       " 'testing': 7204,\n",
       " 'clients': 1140,\n",
       " 'asyncore': 517,\n",
       " 'asynchat': 503,\n",
       " 'showing': 6516,\n",
       " 'age': 170,\n",
       " 'api': 314,\n",
       " 'unwieldy': 7637,\n",
       " 'fortunately': 2858,\n",
       " 'new': 4787,\n",
       " 'alternative': 244,\n",
       " 'aiosmtpd': 196,\n",
       " 'reinvention': 5987,\n",
       " 'asyncio': 508,\n",
       " 'improvements': 3448,\n",
       " 'come': 1240,\n",
       " 'implementation': 3409,\n",
       " 'provides': 5613,\n",
       " 'protocols': 5592,\n",
       " 'controller': 1494,\n",
       " 'exposes': 2605,\n",
       " 'better': 763,\n",
       " 'customization': 1650,\n",
       " 'allowing': 234,\n",
       " 'user': 7720,\n",
       " 'associate': 488,\n",
       " 'handler': 3175,\n",
       " 'process': 5462,\n",
       " 'incoming': 3484,\n",
       " 'messages': 4482,\n",
       " 'having': 3208,\n",
       " 'worry': 8151,\n",
       " 'details': 1901,\n",
       " 'useful': 7711,\n",
       " 'hooks': 3314,\n",
       " 'subclassing': 6909,\n",
       " 'purpose': 5627,\n",
       " 'history': 3294,\n",
       " 'users': 7726,\n",
       " 'extend': 2618,\n",
       " 'implement': 3401,\n",
       " 'specialized': 6694,\n",
       " 'handlers': 3178,\n",
       " 'ensuring': 2392,\n",
       " 'sending': 6411,\n",
       " 'things': 7269,\n",
       " 'examples': 2492,\n",
       " 'taken': 7013,\n",
       " 'gnu': 3040,\n",
       " 'mailman': 4292,\n",
       " 'uses': 7749,\n",
       " 'extensively': 2634,\n",
       " 'smtpd py': 6614,\n",
       " 'py standard': 5640,\n",
       " 'standard library': 6757,\n",
       " 'library years': 4045,\n",
       " 'years common': 8229,\n",
       " 'common tool': 1270,\n",
       " 'tool deploying': 7381,\n",
       " 'deploying smtp': 1866,\n",
       " 'smtp lmtp': 6612,\n",
       " 'lmtp servers': 4193,\n",
       " 'servers handle': 6449,\n",
       " 'handle email': 3173,\n",
       " 'email based': 2314,\n",
       " 'based communication': 667,\n",
       " 'communication python': 1276,\n",
       " 'python providing': 5764,\n",
       " 'providing basic': 5620,\n",
       " 'basic protocol': 680,\n",
       " 'protocol implementations': 5591,\n",
       " 'implementations fundamental': 3420,\n",
       " 'fundamental module': 2947,\n",
       " 'module higher': 4644,\n",
       " 'higher level': 3281,\n",
       " 'level tools': 3991,\n",
       " 'tools lazr': 7403,\n",
       " 'lazr smtptest': 3887,\n",
       " 'smtptest testing': 6616,\n",
       " 'testing email': 7210,\n",
       " 'email clients': 2315,\n",
       " 'clients based': 1141,\n",
       " 'based asyncore': 666,\n",
       " 'asyncore asynchat': 518,\n",
       " 'asynchat smtpd': 504,\n",
       " 'py showing': 5639,\n",
       " 'showing age': 6517,\n",
       " 'age api': 171,\n",
       " 'api unwieldy': 335,\n",
       " 'unwieldy fortunately': 7638,\n",
       " 'fortunately new': 2859,\n",
       " 'new alternative': 4788,\n",
       " 'alternative available': 245,\n",
       " 'available aiosmtpd': 592,\n",
       " 'aiosmtpd modern': 198,\n",
       " 'modern reinvention': 4633,\n",
       " 'reinvention based': 5988,\n",
       " 'based asyncio': 665,\n",
       " 'asyncio improvements': 511,\n",
       " 'improvements come': 3449,\n",
       " 'come new': 1246,\n",
       " 'new implementation': 4799,\n",
       " 'implementation provides': 3416,\n",
       " 'provides servers': 5616,\n",
       " 'servers smtp': 6453,\n",
       " 'lmtp protocols': 4192,\n",
       " 'protocols higher': 5594,\n",
       " 'level controller': 3990,\n",
       " 'controller api': 1495,\n",
       " 'api testing': 333,\n",
       " 'testing smtp': 7226,\n",
       " 'lmtp clients': 4191,\n",
       " 'clients exposes': 1142,\n",
       " 'exposes better': 2606,\n",
       " 'better api': 764,\n",
       " 'api customization': 321,\n",
       " 'customization allowing': 1651,\n",
       " 'allowing user': 237,\n",
       " 'user associate': 7721,\n",
       " 'associate simple': 489,\n",
       " 'simple handler': 6539,\n",
       " 'handler process': 3177,\n",
       " 'process incoming': 5467,\n",
       " 'incoming messages': 3485,\n",
       " 'messages having': 4483,\n",
       " 'having worry': 3213,\n",
       " 'worry details': 8152,\n",
       " 'details protocols': 1903,\n",
       " 'protocols provides': 5595,\n",
       " 'provides useful': 5618,\n",
       " 'useful hooks': 7714,\n",
       " 'hooks subclassing': 3315,\n",
       " 'subclassing talk': 6910,\n",
       " 'talk purpose': 7073,\n",
       " 'purpose history': 5629,\n",
       " 'history smtpd': 3296,\n",
       " 'py aiosmtpd': 5638,\n",
       " 'aiosmtpd users': 199,\n",
       " 'users extend': 7734,\n",
       " 'extend servers': 2619,\n",
       " 'servers implement': 6450,\n",
       " 'implement specialized': 3406,\n",
       " 'specialized handlers': 6695,\n",
       " 'handlers applications': 3179,\n",
       " 'applications use': 396,\n",
       " 'use testing': 7689,\n",
       " 'testing api': 7205,\n",
       " 'api ensuring': 324,\n",
       " 'ensuring email': 2393,\n",
       " 'email sending': 2316,\n",
       " 'sending applications': 6412,\n",
       " 'applications right': 391,\n",
       " 'right things': 6171,\n",
       " 'things examples': 7270,\n",
       " 'examples taken': 2502,\n",
       " 'taken gnu': 7014,\n",
       " 'gnu mailman': 3041,\n",
       " 'mailman uses': 4293,\n",
       " 'uses aiosmtpd': 7750,\n",
       " 'aiosmtpd extensively': 197,\n",
       " 'music': 4685,\n",
       " 'mainly': 4296,\n",
       " 'artistic': 464,\n",
       " 'act': 115,\n",
       " 'inspired': 3553,\n",
       " 'creation': 1615,\n",
       " 'unlike': 7623,\n",
       " 'math': 4412,\n",
       " 'problems': 5441,\n",
       " 'solved': 6657,\n",
       " 'set': 6469,\n",
       " 'formulae': 2850,\n",
       " 'interesting': 3613,\n",
       " 'challenging': 1061,\n",
       " 'producing': 5497,\n",
       " 'unique': 7610,\n",
       " 'infringing': 3521,\n",
       " 'copyright': 1521,\n",
       " 'generated': 2985,\n",
       " 'sound': 6666,\n",
       " 'good': 3058,\n",
       " 'sounds': 6670,\n",
       " 'subjective': 6915,\n",
       " 'varies': 7827,\n",
       " 'culture': 1634,\n",
       " 'artificial': 461,\n",
       " 'network': 4768,\n",
       " 'wide': 8037,\n",
       " 'range': 5856,\n",
       " 'image': 3375,\n",
       " 'processing': 5478,\n",
       " 'natural': 4726,\n",
       " 'language': 3826,\n",
       " 'time': 7311,\n",
       " 'series': 6429,\n",
       " 'prediction': 5374,\n",
       " 'usage': 7648,\n",
       " 'art': 456,\n",
       " 'create': 1600,\n",
       " 'models': 4607,\n",
       " 'used': 7692,\n",
       " 'produce': 5489,\n",
       " 'catering': 1009,\n",
       " 'particularly': 5124,\n",
       " 'bollywood': 807,\n",
       " 'exquisite': 2616,\n",
       " 'piece': 5220,\n",
       " 'model': 4570,\n",
       " 'helps': 3264,\n",
       " 'automated': 563,\n",
       " 'feature': 2712,\n",
       " 'extraction': 2637,\n",
       " 'order': 4984,\n",
       " 'automate': 556,\n",
       " 'generation': 2994,\n",
       " 'able': 67,\n",
       " 'remember': 6026,\n",
       " 'learned': 3927,\n",
       " 'features': 2719,\n",
       " 'longer': 4218,\n",
       " 'period': 5196,\n",
       " 'achieved': 109,\n",
       " 'special': 6689,\n",
       " 'type': 7542,\n",
       " 'recurrent': 5946,\n",
       " 'rnn': 6185,\n",
       " 'called': 946,\n",
       " 'lstm': 4263,\n",
       " 'long': 4213,\n",
       " 'short': 6510,\n",
       " 'term': 7174,\n",
       " 'memory': 4461,\n",
       " 'complex': 1335,\n",
       " 'easier': 2227,\n",
       " 'inbuilt': 3459,\n",
       " 'libraries': 4000,\n",
       " 'keras': 3766,\n",
       " 'theano': 7256,\n",
       " 'backend': 634,\n",
       " 'allows': 238,\n",
       " 'easy': 2245,\n",
       " 'fast': 2683,\n",
       " 'prototyping': 5596,\n",
       " 'packages': 5057,\n",
       " 'numpy': 4877,\n",
       " 'scipy': 6340,\n",
       " 'mathematical': 4415,\n",
       " 'computation': 1376,\n",
       " 'input': 3538,\n",
       " 'vectors': 7859,\n",
       " 'reading': 5890,\n",
       " 'writing': 8190,\n",
       " 'wav': 7954,\n",
       " 'files': 2745,\n",
       " 'respectively': 6092,\n",
       " 'architecture': 432,\n",
       " 'makes': 4345,\n",
       " 'numerous': 4875,\n",
       " 'samples': 6265,\n",
       " 'train': 7458,\n",
       " 'adequate': 143,\n",
       " 'number': 4864,\n",
       " 'iterations': 3716,\n",
       " 'training': 7463,\n",
       " 'generates': 2988,\n",
       " 'original': 5000,\n",
       " 'steps': 6827,\n",
       " 'involved': 3696,\n",
       " 'preprocessing': 5386,\n",
       " 'data': 1668,\n",
       " 'generating': 2990,\n",
       " 'trained': 7460,\n",
       " 'discussed': 2070,\n",
       " 'cover': 1559,\n",
       " 'challenges': 1054,\n",
       " 'tradeoffs': 7451,\n",
       " 'algorithmic': 212,\n",
       " 'music mainly': 4690,\n",
       " 'mainly artistic': 4297,\n",
       " 'artistic act': 465,\n",
       " 'act inspired': 116,\n",
       " 'inspired creation': 3554,\n",
       " 'creation unlike': 1618,\n",
       " 'unlike traditional': 7624,\n",
       " 'traditional math': 7457,\n",
       " 'math problems': 4414,\n",
       " 'problems music': 5451,\n",
       " 'music solved': 4692,\n",
       " 'solved simple': 6659,\n",
       " 'simple set': 6544,\n",
       " 'set formulae': 6473,\n",
       " 'formulae interesting': 2851,\n",
       " 'interesting challenging': 3614,\n",
       " 'challenging producing': 1064,\n",
       " 'producing unique': 5498,\n",
       " 'unique music': 7611,\n",
       " 'music infringing': 4689,\n",
       " 'infringing copyright': 3522,\n",
       " 'copyright generated': 1522,\n",
       " 'generated music': 2986,\n",
       " 'music sound': 4693,\n",
       " 'sound good': 6667,\n",
       " 'good sounds': 3073,\n",
       " 'sounds good': 6671,\n",
       " 'good subjective': 3074,\n",
       " 'subjective varies': 6916,\n",
       " 'varies culture': 7828,\n",
       " 'culture culture': 1636,\n",
       " 'culture artificial': 1635,\n",
       " 'artificial neural': 463,\n",
       " 'neural network': 4785,\n",
       " 'network deep': 4771,\n",
       " 'learning wide': 3953,\n",
       " 'wide range': 8038,\n",
       " 'range applications': 5857,\n",
       " 'applications image': 385,\n",
       " 'image processing': 3377,\n",
       " 'processing natural': 5484,\n",
       " 'natural language': 4728,\n",
       " 'language processing': 3837,\n",
       " 'processing time': 5488,\n",
       " 'time series': 7331,\n",
       " 'series prediction': 6433,\n",
       " 'prediction usage': 5376,\n",
       " 'usage art': 7649,\n",
       " 'art use': 458,\n",
       " 'use deep': 7658,\n",
       " 'learning create': 3936,\n",
       " 'create music': 1607,\n",
       " 'music talk': 4694,\n",
       " 'talk deep': 7039,\n",
       " 'learning models': 3946,\n",
       " 'models used': 4620,\n",
       " 'used produce': 7705,\n",
       " 'produce music': 5491,\n",
       " 'music catering': 4686,\n",
       " 'catering particularly': 1010,\n",
       " 'particularly bollywood': 5125,\n",
       " 'bollywood talk': 808,\n",
       " 'talk exquisite': 7051,\n",
       " 'exquisite piece': 2617,\n",
       " 'piece art': 5221,\n",
       " 'art music': 457,\n",
       " 'music generated': 4687,\n",
       " 'generated using': 2987,\n",
       " 'using deep': 7759,\n",
       " 'learning model': 3945,\n",
       " 'model helps': 4586,\n",
       " 'helps automated': 3265,\n",
       " 'automated feature': 564,\n",
       " 'feature extraction': 2715,\n",
       " 'extraction order': 2638,\n",
       " 'order automate': 4985,\n",
       " 'automate music': 559,\n",
       " 'music generation': 4688,\n",
       " 'generation model': 2995,\n",
       " 'model able': 4571,\n",
       " 'able remember': 72,\n",
       " 'remember learned': 6027,\n",
       " 'learned features': 3928,\n",
       " 'features longer': 2724,\n",
       " 'longer period': 4219,\n",
       " 'period time': 5197,\n",
       " 'time achieved': 7312,\n",
       " 'achieved special': 110,\n",
       " 'special type': 6693,\n",
       " 'type recurrent': 7549,\n",
       " 'recurrent neural': 5947,\n",
       " 'network rnn': 4775,\n",
       " 'rnn called': 6186,\n",
       " 'called lstm': 950,\n",
       " 'lstm long': 4264,\n",
       " 'long short': 4215,\n",
       " 'short term': 6511,\n",
       " 'term memory': 7177,\n",
       " 'memory network': 4463,\n",
       " 'network implementation': 4773,\n",
       " 'implementation complex': 3411,\n",
       " 'complex model': 1342,\n",
       " 'model easier': 4580,\n",
       " 'easier using': 2237,\n",
       " 'using inbuilt': 7766,\n",
       " 'inbuilt python': 3460,\n",
       " 'python libraries': 5736,\n",
       " 'libraries keras': 4017,\n",
       " 'keras theano': 3767,\n",
       " 'theano backend': 7257,\n",
       " 'backend allows': 635,\n",
       " 'allows easy': 240,\n",
       " 'easy fast': 2250,\n",
       " 'fast prototyping': 2691,\n",
       " 'prototyping packages': 5598,\n",
       " 'packages like': 5060,\n",
       " 'like numpy': 4085,\n",
       " 'numpy scipy': 4882,\n",
       " 'scipy used': 6342,\n",
       " 'used easier': 7697,\n",
       " 'easier mathematical': 2233,\n",
       " 'mathematical computation': 4416,\n",
       " 'computation input': 1377,\n",
       " 'input vectors': 3541,\n",
       " 'vectors reading': 7860,\n",
       " 'reading writing': 5893,\n",
       " 'writing wav': 8197,\n",
       " 'wav files': 7955,\n",
       " 'files respectively': 2748,\n",
       " 'respectively neural': 6093,\n",
       " 'network architecture': 4770,\n",
       " 'architecture makes': 435,\n",
       " 'makes use': 4352,\n",
       " 'use numerous': 7675,\n",
       " 'numerous music': 4876,\n",
       " 'music samples': 4691,\n",
       " 'samples train': 6266,\n",
       " 'train model': 7459,\n",
       " 'model adequate': 4572,\n",
       " 'adequate number': 144,\n",
       " 'number iterations': 4865,\n",
       " 'iterations training': 3717,\n",
       " 'training time': 7467,\n",
       " 'time model': 7323,\n",
       " 'model generates': 4584,\n",
       " 'generates music': 2989,\n",
       " 'music unique': 4696,\n",
       " 'unique original': 7612,\n",
       " 'original talk': 5002,\n",
       " 'talk steps': 7078,\n",
       " 'steps involved': 6829,\n",
       " 'involved preprocessing': 3699,\n",
       " 'preprocessing data': 5387,\n",
       " 'data training': 1721,\n",
       " 'training model': 7465,\n",
       " 'model testing': 4594,\n",
       " 'testing model': 7219,\n",
       " 'model generating': 4585,\n",
       " 'generating music': 2993,\n",
       " 'music trained': 4695,\n",
       " 'trained model': 7462,\n",
       " 'model discussed': 4578,\n",
       " 'discussed talk': 2071,\n",
       " 'talk cover': 7037,\n",
       " 'cover challenges': 1563,\n",
       " 'challenges tradeoffs': 1060,\n",
       " 'tradeoffs algorithmic': 7452,\n",
       " 'algorithmic music': 213,\n",
       " 'reinforcement': 5983,\n",
       " 'rl': 6179,\n",
       " 'subfield': 6911,\n",
       " 'focused': 2812,\n",
       " 'building': 885,\n",
       " 'agents': 174,\n",
       " 'software': 6619,\n",
       " 'robustly': 6200,\n",
       " 'achieve': 105,\n",
       " 'desired': 1899,\n",
       " 'objective': 4894,\n",
       " 'varying': 7846,\n",
       " 'states': 6791,\n",
       " 'introduction': 3671,\n",
       " 'provide': 5602,\n",
       " 'overview': 5035,\n",
       " 'build': 858,\n",
       " 'terminology': 7179,\n",
       " 'jupyter': 3749,\n",
       " 'notebook': 4845,\n",
       " 'outlining': 5019,\n",
       " 'algorithms': 214,\n",
       " 'policies': 5301,\n",
       " 'strategies': 6849,\n",
       " 'agent': 172,\n",
       " 'visualize': 7909,\n",
       " 'pandas': 5088,\n",
       " 'seaborn': 6362,\n",
       " 'newer': 4810,\n",
       " 'developments': 1954,\n",
       " 'apply': 400,\n",
       " 'improve': 3442,\n",
       " 'performance': 5180,\n",
       " 'discuss': 2050,\n",
       " 'latest': 3870,\n",
       " 'openai': 4939,\n",
       " 'gym': 3157,\n",
       " 'universe': 7619,\n",
       " 'deepmind': 1813,\n",
       " 'lab': 3810,\n",
       " 'reinforcement learning': 5984,\n",
       " 'learning rl': 3950,\n",
       " 'rl subfield': 6181,\n",
       " 'subfield machine': 6912,\n",
       " 'learning focused': 3940,\n",
       " 'focused building': 2813,\n",
       " 'building agents': 886,\n",
       " 'agents software': 175,\n",
       " 'software robustly': 6638,\n",
       " 'robustly achieve': 6201,\n",
       " 'achieve desired': 107,\n",
       " 'desired objective': 1900,\n",
       " 'objective varying': 4896,\n",
       " 'varying states': 7847,\n",
       " 'states world': 6792,\n",
       " 'world introduction': 8140,\n",
       " 'introduction provide': 3678,\n",
       " 'provide overview': 5610,\n",
       " 'overview rl': 5039,\n",
       " 'rl tools': 6182,\n",
       " 'tools build': 7397,\n",
       " 'build agents': 859,\n",
       " 'agents talk': 176,\n",
       " 'talk provide': 7071,\n",
       " 'overview terminology': 5040,\n",
       " 'terminology reinforcement': 7180,\n",
       " 'learning jupyter': 3942,\n",
       " 'jupyter notebook': 3750,\n",
       " 'notebook outlining': 4847,\n",
       " 'outlining basic': 5020,\n",
       " 'basic algorithms': 674,\n",
       " 'algorithms learn': 217,\n",
       " 'learn policies': 3919,\n",
       " 'policies strategies': 5302,\n",
       " 'strategies agent': 6850,\n",
       " 'agent visualize': 173,\n",
       " 'visualize numpy': 7911,\n",
       " 'numpy pandas': 4881,\n",
       " 'pandas seaborn': 5096,\n",
       " 'seaborn newer': 6364,\n",
       " 'newer developments': 4811,\n",
       " 'developments reinforcement': 1955,\n",
       " 'learning apply': 3933,\n",
       " 'apply deep': 402,\n",
       " 'learning improve': 3941,\n",
       " 'improve performance': 3444,\n",
       " 'performance discuss': 5182,\n",
       " 'discuss deep': 2053,\n",
       " 'deep reinforcement': 1810,\n",
       " 'learning use': 3952,\n",
       " 'learning libraries': 3944,\n",
       " 'libraries tensorflow': 4025,\n",
       " 'tensorflow theano': 7173,\n",
       " 'theano latest': 7259,\n",
       " 'latest rl': 3874,\n",
       " 'rl libraries': 6180,\n",
       " 'libraries openai': 4020,\n",
       " 'openai gym': 4940,\n",
       " 'gym openai': 3158,\n",
       " 'openai universe': 4941,\n",
       " 'universe deepmind': 7620,\n",
       " 'deepmind lab': 1814,\n",
       " 'overviews': 5041,\n",
       " 'async': 499,\n",
       " 'await': 616,\n",
       " 'asynchronous': 505,\n",
       " 'generators': 2996,\n",
       " 'comprehensions': 1373,\n",
       " 'uvloop': 7793,\n",
       " 'frameworks': 2879,\n",
       " 'ideas': 3357,\n",
       " 'headed': 3218,\n",
       " 'expect': 2535,\n",
       " 'talk overviews': 7068,\n",
       " 'overviews async': 5042,\n",
       " 'async await': 500,\n",
       " 'await asynchronous': 617,\n",
       " 'asynchronous generators': 506,\n",
       " 'generators comprehensions': 2997,\n",
       " 'comprehensions python': 1375,\n",
       " 'python asyncio': 5671,\n",
       " 'asyncio module': 512,\n",
       " 'module ll': 4645,\n",
       " 'll discuss': 4150,\n",
       " 'discuss asyncio': 2051,\n",
       " 'asyncio used': 516,\n",
       " 'used modern': 7704,\n",
       " 'modern applications': 4624,\n",
       " 'applications services': 392,\n",
       " 'services uvloop': 6466,\n",
       " 'uvloop asyncio': 7794,\n",
       " 'asyncio frameworks': 509,\n",
       " 'frameworks libraries': 2882,\n",
       " 'libraries use': 4026,\n",
       " 'use ll': 7669,\n",
       " 'll share': 4180,\n",
       " 'share ideas': 6497,\n",
       " 'ideas asyncio': 3358,\n",
       " 'asyncio headed': 510,\n",
       " 'headed expect': 3219,\n",
       " 'expect python': 2536,\n",
       " 'package': 5045,\n",
       " 'hear': 3226,\n",
       " 'lots': 4253,\n",
       " 'people': 5153,\n",
       " 'talking': 7095,\n",
       " 'programming': 5531,\n",
       " 'favorable': 2704,\n",
       " 'tell': 7153,\n",
       " 'fever': 2734,\n",
       " 'regular': 5976,\n",
       " 'existed': 2531,\n",
       " 'introduction asyncio': 3672,\n",
       " 'asyncio package': 513,\n",
       " 'package python': 5055,\n",
       " 'python hear': 5722,\n",
       " 'hear lots': 3228,\n",
       " 'lots people': 4254,\n",
       " 'people talking': 5161,\n",
       " 'talking asynchronous': 7096,\n",
       " 'asynchronous programming': 507,\n",
       " 'programming favorable': 5535,\n",
       " 'favorable way': 2705,\n",
       " 'way talk': 7977,\n",
       " 'talk tell': 7082,\n",
       " 'tell async': 7154,\n",
       " 'async fever': 501,\n",
       " 'fever regular': 2735,\n",
       " 'regular python': 5978,\n",
       " 'frameworks existed': 2881,\n",
       " 'existed long': 2532,\n",
       " 'known': 3802,\n",
       " 'cloud': 1147,\n",
       " 'vendors': 7868,\n",
       " 'ui': 7563,\n",
       " 'starting': 6779,\n",
       " 'automating': 573,\n",
       " 'operations': 4961,\n",
       " 'important': 3427,\n",
       " 'boto3': 813,\n",
       " 'great': 3108,\n",
       " 'pythonic': 5798,\n",
       " 'correctly': 1540,\n",
       " 'subtle': 6922,\n",
       " 'ami': 258,\n",
       " 'builds': 902,\n",
       " 'formation': 2844,\n",
       " 'templates': 7160,\n",
       " 's3': 6248,\n",
       " 'bucket': 851,\n",
       " 'management': 4366,\n",
       " 'aws best': 631,\n",
       " 'best known': 754,\n",
       " 'known cloud': 3803,\n",
       " 'cloud vendors': 1152,\n",
       " 'vendors using': 7871,\n",
       " 'using web': 7786,\n",
       " 'web ui': 8007,\n",
       " 'ui fine': 7564,\n",
       " 'fine starting': 2771,\n",
       " 'starting automating': 6780,\n",
       " 'automating cloud': 575,\n",
       " 'cloud operations': 1151,\n",
       " 'operations important': 4963,\n",
       " 'important boto3': 3429,\n",
       " 'boto3 provides': 814,\n",
       " 'provides great': 5614,\n",
       " 'great pythonic': 3114,\n",
       " 'pythonic api': 5799,\n",
       " 'api aws': 316,\n",
       " 'aws using': 633,\n",
       " 'using correctly': 7757,\n",
       " 'correctly subtle': 1542,\n",
       " 'subtle talk': 6923,\n",
       " 'cover automate': 1561,\n",
       " 'automate ami': 557,\n",
       " 'ami builds': 259,\n",
       " 'builds building': 903,\n",
       " 'building cloud': 889,\n",
       " 'cloud formation': 1150,\n",
       " 'formation templates': 2845,\n",
       " 'templates automating': 7161,\n",
       " 'automating s3': 577,\n",
       " 's3 bucket': 6249,\n",
       " 'bucket management': 852,\n",
       " 'decorators': 1799,\n",
       " 'syntactically': 6984,\n",
       " 'pleasing': 5284,\n",
       " 'modifying': 4638,\n",
       " 'behavior': 731,\n",
       " 'functions': 2932,\n",
       " 'highly': 3285,\n",
       " 'opaque': 4928,\n",
       " 'beginners': 727,\n",
       " 'took': 7375,\n",
       " 'write': 8173,\n",
       " 'confident': 1430,\n",
       " 'felt': 2728,\n",
       " 'magical': 4290,\n",
       " 'goal': 3042,\n",
       " 'demystify': 1850,\n",
       " 'methodically': 4501,\n",
       " 'stepping': 6825,\n",
       " 'closures': 1145,\n",
       " 'scopes': 6343,\n",
       " 'compiled': 1324,\n",
       " 'decorators syntactically': 1802,\n",
       " 'syntactically pleasing': 6985,\n",
       " 'pleasing way': 5285,\n",
       " 'way modifying': 7970,\n",
       " 'modifying behavior': 4639,\n",
       " 'behavior functions': 732,\n",
       " 'functions python': 2942,\n",
       " 'python highly': 5725,\n",
       " 'highly opaque': 3287,\n",
       " 'opaque python': 4930,\n",
       " 'python beginners': 5675,\n",
       " 'beginners took': 728,\n",
       " 'took learn': 7376,\n",
       " 'learn write': 3926,\n",
       " 'write confident': 8175,\n",
       " 'confident writing': 1431,\n",
       " 'writing decorators': 8193,\n",
       " 'decorators felt': 1800,\n",
       " 'felt like': 2729,\n",
       " 'like magical': 4082,\n",
       " 'magical goal': 4291,\n",
       " 'goal talk': 3045,\n",
       " 'talk demystify': 7042,\n",
       " 'demystify decorators': 1851,\n",
       " 'decorators methodically': 1801,\n",
       " 'methodically stepping': 4502,\n",
       " 'stepping work': 6826,\n",
       " 'work way': 8099,\n",
       " 'way ll': 7967,\n",
       " 'll touch': 4186,\n",
       " 'touch closures': 7427,\n",
       " 'closures scopes': 1146,\n",
       " 'scopes python': 6344,\n",
       " 'python compiled': 5685,\n",
       " 'designing': 1892,\n",
       " 'command': 1256,\n",
       " 'line': 4108,\n",
       " 'look': 4221,\n",
       " 'archaic': 430,\n",
       " 'compared': 1301,\n",
       " 'graphical': 3102,\n",
       " 'interfaces': 3623,\n",
       " 'discoverability': 2046,\n",
       " 'big': 771,\n",
       " 'issue': 3710,\n",
       " 'proactive': 5421,\n",
       " 'hard': 3189,\n",
       " 'alleviate': 223,\n",
       " 'did': 1983,\n",
       " 'pgcli': 5209,\n",
       " 'mycli': 4701,\n",
       " 'overcome': 5029,\n",
       " 'apps': 426,\n",
       " 'shine': 6505,\n",
       " 'drawn': 2195,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `get_feature_names` function on the Tfidf `vectorizer` to get the features (terms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>terms</th>\n",
       "      <th>occurrences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>python</td>\n",
       "      <td>4.241994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>ll</td>\n",
       "      <td>2.649221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>data</td>\n",
       "      <td>2.597951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>talk</td>\n",
       "      <td>2.472821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>code</td>\n",
       "      <td>2.044565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7651</th>\n",
       "      <td>use</td>\n",
       "      <td>1.559560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7754</th>\n",
       "      <td>using</td>\n",
       "      <td>1.449880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>application</td>\n",
       "      <td>1.434132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>tools</td>\n",
       "      <td>1.404280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000</th>\n",
       "      <td>libraries</td>\n",
       "      <td>1.348243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>like</td>\n",
       "      <td>1.328287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7311</th>\n",
       "      <td>time</td>\n",
       "      <td>1.315424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7204</th>\n",
       "      <td>testing</td>\n",
       "      <td>1.314759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>learn</td>\n",
       "      <td>1.312405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7992</th>\n",
       "      <td>web</td>\n",
       "      <td>1.239668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>api</td>\n",
       "      <td>1.226140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>users</td>\n",
       "      <td>1.218568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4318</th>\n",
       "      <td>make</td>\n",
       "      <td>1.212322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4570</th>\n",
       "      <td>model</td>\n",
       "      <td>1.182129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>build</td>\n",
       "      <td>1.168728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3931</th>\n",
       "      <td>learning</td>\n",
       "      <td>1.155930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4787</th>\n",
       "      <td>new</td>\n",
       "      <td>1.153504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7958</th>\n",
       "      <td>way</td>\n",
       "      <td>1.117225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7238</th>\n",
       "      <td>text</td>\n",
       "      <td>1.101249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6619</th>\n",
       "      <td>software</td>\n",
       "      <td>1.099523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8080</th>\n",
       "      <td>work</td>\n",
       "      <td>1.074052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>different</td>\n",
       "      <td>1.038002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>world</td>\n",
       "      <td>0.982830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>good</td>\n",
       "      <td>0.981586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7063</th>\n",
       "      <td>talk ll</td>\n",
       "      <td>0.956139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>custom corpus</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>language reduce</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>data discourse</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>language models</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7249</th>\n",
       "      <td>text machine</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>learning large</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7246</th>\n",
       "      <td>text doing</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>containing text</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>limits terms</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>limits</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>like siri</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4084</th>\n",
       "      <td>like novelties</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4068</th>\n",
       "      <td>like bloggers</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>components establish</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>composite</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036</th>\n",
       "      <td>library performs</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>composites</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>composites recombine</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>computation modeling</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>compute composites</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5337</th>\n",
       "      <td>potential performance</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4006</th>\n",
       "      <td>libraries built</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7239</th>\n",
       "      <td>text audio</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>consider data</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>consisting</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>consisting hundreds</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>construction</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>construction data</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>containing natural</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6949</th>\n",
       "      <td>support machine</td>\n",
       "      <td>0.042758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8244 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      terms  occurrences\n",
       "5666                 python     4.241994\n",
       "4143                     ll     2.649221\n",
       "1668                   data     2.597951\n",
       "7025                   talk     2.472821\n",
       "1157                   code     2.044565\n",
       "7651                    use     1.559560\n",
       "7754                  using     1.449880\n",
       "357             application     1.434132\n",
       "7394                  tools     1.404280\n",
       "4000              libraries     1.348243\n",
       "4065                   like     1.328287\n",
       "7311                   time     1.315424\n",
       "7204                testing     1.314759\n",
       "3901                  learn     1.312405\n",
       "7992                    web     1.239668\n",
       "314                     api     1.226140\n",
       "7726                  users     1.218568\n",
       "4318                   make     1.212322\n",
       "4570                  model     1.182129\n",
       "858                   build     1.168728\n",
       "3931               learning     1.155930\n",
       "4787                    new     1.153504\n",
       "7958                    way     1.117225\n",
       "7238                   text     1.101249\n",
       "6619               software     1.099523\n",
       "8080                   work     1.074052\n",
       "1991              different     1.038002\n",
       "8133                  world     0.982830\n",
       "3058                   good     0.981586\n",
       "7063                talk ll     0.956139\n",
       "...                     ...          ...\n",
       "1645          custom corpus     0.042758\n",
       "3838        language reduce     0.042758\n",
       "1679         data discourse     0.042758\n",
       "3834        language models     0.042758\n",
       "7249           text machine     0.042758\n",
       "3943         learning large     0.042758\n",
       "7246             text doing     0.042758\n",
       "1477        containing text     0.042758\n",
       "4107           limits terms     0.042758\n",
       "4106                 limits     0.042758\n",
       "4091              like siri     0.042758\n",
       "4084         like novelties     0.042758\n",
       "4068          like bloggers     0.042758\n",
       "1362   components establish     0.042758\n",
       "1367              composite     0.042758\n",
       "4036       library performs     0.042758\n",
       "1369             composites     0.042758\n",
       "1370   composites recombine     0.042758\n",
       "1378   computation modeling     0.042758\n",
       "1387     compute composites     0.042758\n",
       "5337  potential performance     0.042758\n",
       "4006        libraries built     0.042758\n",
       "7239             text audio     0.042758\n",
       "1449          consider data     0.042758\n",
       "1463             consisting     0.042758\n",
       "1464    consisting hundreds     0.042758\n",
       "1467           construction     0.042758\n",
       "1468      construction data     0.042758\n",
       "1476     containing natural     0.042758\n",
       "6949        support machine     0.042758\n",
       "\n",
       "[8244 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrences = np.asarray(vectorized_text_labeled.sum(axis=0)).ravel()\n",
    "terms = (vectorizer.get_feature_names())\n",
    "counts_df = pd.DataFrame({'terms': terms, 'occurrences': occurrences}).sort_values('occurrences', ascending=False)\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3 Transform documents for prediction into document-term matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the data on which we will do our predictions, we will use the [transform](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer.transform) method to get the document-term matrix.\n",
    "We will use this later, once we have our model ready. What should be the input to the `transform` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text_predict = vectorizer.transform( description_predict )\n",
    "vectorized_text_predict.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Split into training and testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we split our data into training set and testing set. This allows us to do cross validation and avoid overfitting. Use the `train_test_split` method from `sklearn.model_selection` to split the `vectorized_text_labeled` into training and testing set with the test size as one third of the size (0.3) of the labeled.\n",
    "\n",
    "[Here](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) is the documentation for the function. The example usage should be helpful for understanding what `X_train, X_test, y_train, y_test` tuple represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = df[df.year == 2017]['label']\n",
    "test_size= 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_text_labeled, labels, test_size=test_size, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1 Inspect the shape of each output of train_test_split\n",
    "For each of the output above, get the shape of the matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 8244)\n",
      "(29, 8244)\n",
      "(66,)\n",
      "(29,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Train the model\n",
    "Finally we get to the stage for training the model. We are going to use a linear [support vector classifier](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) and check its accuracy by using the `classification_report` function. Note that we have not done any parameter tuning done yet, so your model might not give you the best results. Like `TfIdfVectorizer` you can come back and tune these parameters later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "classifier = LinearSVC(verbose=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model by using the the `classification_report` method from the [classification_report](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html). What are the values of precision, recall and f1-scores? They are defined [here](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.71      1.00      0.83        20\n",
      "        1.0       1.00      0.11      0.20         9\n",
      "\n",
      "avg / total       0.80      0.72      0.64        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "report = sklearn.metrics.classification_report( y_test , y_pred )\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: Make Predictions\n",
    "Use the model to predict which 2018 talks the user should go to. Plugin `vectorized_text_predict` from exercise 2.3 to get the `predicted_talks_vector` into the predict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_talks_vector = classifier.predict( vectorized_text_predict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `predicted_talk_indexes` get  the talk id, description, presenters, title and location and talk date.\n",
    "How many talks should the user go to according to your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018 = df[df.year==2018]\n",
    "predicted_talk_indexes = predicted_talks_vector.nonzero()[0] + len(df[df.year==2017])\n",
    "\n",
    "df_2018_talks = df_2018.loc[predicted_talk_indexes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "You might not be very happy with the results. You might want to reduce the manual steps for tuning the parameters. So where do you go from here?\n",
    "There are three specific next steps that can make this better.\n",
    "* [Spacy](https://spacy.io/) - This is an industrial strength natural language processeing libray that has a friendly api. This would be useful in your feature extraction steps.\n",
    "* Try using a different algorithm. [There is a lot](http://scikit-learn.org/stable/supervised_learning.html) to choose from.\n",
    "* [Pipeline](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) together make a great combination for automating the process of searching for the best models and parameters that accurately represent the patterns in your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>presenters</th>\n",
       "      <th>date_created</th>\n",
       "      <th>date_modified</th>\n",
       "      <th>location</th>\n",
       "      <th>talk_dt</th>\n",
       "      <th>year</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>103</td>\n",
       "      <td>Bayesian Non-parametric Models for Data Scienc...</td>\n",
       "      <td>Nowadays, there are many ways of building data...</td>\n",
       "      <td>Christopher Fonnesbeck</td>\n",
       "      <td>2018-04-19 00:59:20.691667</td>\n",
       "      <td>2018-04-19 00:59:20.691667</td>\n",
       "      <td>Global Center Ballroom AB</td>\n",
       "      <td>2018-03-29 13:40:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>104</td>\n",
       "      <td>Behavior-Driven Python</td>\n",
       "      <td>Behavior-Driven Development (BDD) is gaining p...</td>\n",
       "      <td>Andrew Knight</td>\n",
       "      <td>2018-04-19 00:59:20.695767</td>\n",
       "      <td>2018-04-19 00:59:20.695767</td>\n",
       "      <td>Grand Ballroom A</td>\n",
       "      <td>2018-03-29 12:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>106</td>\n",
       "      <td>Beyond Unit Tests: Taking Your Testing to the ...</td>\n",
       "      <td>You've used pytest and you've used mypy, but b...</td>\n",
       "      <td>Hillel Wayne</td>\n",
       "      <td>2018-04-19 00:59:20.703329</td>\n",
       "      <td>2018-04-19 00:59:20.703329</td>\n",
       "      <td>Room 26A/B/C</td>\n",
       "      <td>2018-03-29 12:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>113</td>\n",
       "      <td>By the Numbers: Python Community Trends in 201...</td>\n",
       "      <td>Want to know about the latest trends in the Py...</td>\n",
       "      <td>Dmitry Filippov, Ewa Jodlowska</td>\n",
       "      <td>2018-04-19 00:59:20.738717</td>\n",
       "      <td>2018-04-19 00:59:20.738717</td>\n",
       "      <td>Room 26A/B/C</td>\n",
       "      <td>2018-03-29 13:55:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>114</td>\n",
       "      <td>Clearer Code at Scale: Static Types at Zulip a...</td>\n",
       "      <td>Python now offers static types! Companies like...</td>\n",
       "      <td>Greg Price</td>\n",
       "      <td>2018-04-19 00:59:20.744340</td>\n",
       "      <td>2018-04-19 00:59:20.744340</td>\n",
       "      <td>Grand Ballroom B</td>\n",
       "      <td>2018-03-29 13:50:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>126</td>\n",
       "      <td>Demystifying the Patch Function</td>\n",
       "      <td>One of the most challenging and important thin...</td>\n",
       "      <td>Lisa Roach</td>\n",
       "      <td>2018-04-19 00:59:20.802335</td>\n",
       "      <td>2018-04-19 00:59:20.802335</td>\n",
       "      <td>Grand Ballroom B</td>\n",
       "      <td>2018-03-29 12:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>132</td>\n",
       "      <td>Elegant Solutions For Everyday Python Problems</td>\n",
       "      <td>Are you an intermediate python developer looki...</td>\n",
       "      <td>Nina Zakharenko</td>\n",
       "      <td>2018-04-19 00:59:20.828630</td>\n",
       "      <td>2018-04-19 00:59:20.828630</td>\n",
       "      <td>Room 26A/B/C</td>\n",
       "      <td>2018-03-29 17:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>135</td>\n",
       "      <td>Fighting the Good Fight: Python 3 in your orga...</td>\n",
       "      <td>Today, services built on Python 3.6.3 are wide...</td>\n",
       "      <td>Jason Fried</td>\n",
       "      <td>2018-04-19 00:59:20.840462</td>\n",
       "      <td>2018-04-19 00:59:20.840462</td>\n",
       "      <td>Grand Ballroom B</td>\n",
       "      <td>2018-03-29 16:30:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>139</td>\n",
       "      <td>How Netflix does failovers in 7 minutes flat</td>\n",
       "      <td>During peak hours, Netflix video streams make ...</td>\n",
       "      <td>Amjith Ramanujam</td>\n",
       "      <td>2018-04-19 00:59:20.860729</td>\n",
       "      <td>2018-04-19 00:59:20.860729</td>\n",
       "      <td>Global Center Ballroom AB</td>\n",
       "      <td>2018-03-29 11:30:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>140</td>\n",
       "      <td>HOWTO Write a Function</td>\n",
       "      <td>A function is a small chunk of code that does ...</td>\n",
       "      <td>Jack Diederich</td>\n",
       "      <td>2018-04-19 00:59:20.869047</td>\n",
       "      <td>2018-04-19 00:59:20.869047</td>\n",
       "      <td>Room 26A/B/C</td>\n",
       "      <td>2018-03-29 12:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>145</td>\n",
       "      <td>Inside the Cheeseshop: How Python Packaging Works</td>\n",
       "      <td>Questions and confusion about the Python packa...</td>\n",
       "      <td>Dustin Ingram</td>\n",
       "      <td>2018-04-19 00:59:20.891093</td>\n",
       "      <td>2018-04-19 00:59:20.891093</td>\n",
       "      <td>Room 26A/B/C</td>\n",
       "      <td>2018-03-29 11:30:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>One weird trick to becoming a better software ...</td>\n",
       "      <td>Those of us who have worked in software develo...</td>\n",
       "      <td>Esther Nam</td>\n",
       "      <td>2018-04-19 00:59:20.906538</td>\n",
       "      <td>2018-04-19 00:59:20.906538</td>\n",
       "      <td>Global Center Ballroom AB</td>\n",
       "      <td>2018-03-29 12:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>152</td>\n",
       "      <td>Practical Sphinx</td>\n",
       "      <td>Each member of your project team uses somethin...</td>\n",
       "      <td>Carol Willing</td>\n",
       "      <td>2018-04-19 00:59:20.920561</td>\n",
       "      <td>2018-04-19 00:59:20.920561</td>\n",
       "      <td>Grand Ballroom A</td>\n",
       "      <td>2018-03-29 11:30:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>155</td>\n",
       "      <td>Python 3: ten years later</td>\n",
       "      <td>Looking back at Python evolutions over the las...</td>\n",
       "      <td>Victor Stinner</td>\n",
       "      <td>2018-04-19 00:59:20.940580</td>\n",
       "      <td>2018-04-19 00:59:20.940580</td>\n",
       "      <td>Grand Ballroom B</td>\n",
       "      <td>2018-03-29 15:15:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>166</td>\n",
       "      <td>Solve Your Problem With Sloppy Python</td>\n",
       "      <td>Stop writing crappy shell scripts—write crappy...</td>\n",
       "      <td>Larry Hastings</td>\n",
       "      <td>2018-04-19 00:59:21.001207</td>\n",
       "      <td>2018-04-19 00:59:21.001207</td>\n",
       "      <td>Grand Ballroom C</td>\n",
       "      <td>2018-03-29 10:50:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>172</td>\n",
       "      <td>The AST and Me</td>\n",
       "      <td>Get under the hood and learn about Python's be...</td>\n",
       "      <td>Emily Morehouse-Valcarcel</td>\n",
       "      <td>2018-04-19 00:59:21.028885</td>\n",
       "      <td>2018-04-19 00:59:21.028885</td>\n",
       "      <td>Grand Ballroom B</td>\n",
       "      <td>2018-03-29 15:15:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>178</td>\n",
       "      <td>There and Back Again: Disable and re-enable ga...</td>\n",
       "      <td>Python's cyclic garbage collector wonderfully ...</td>\n",
       "      <td>Zekun Li</td>\n",
       "      <td>2018-04-19 00:59:21.055058</td>\n",
       "      <td>2018-04-19 00:59:21.055058</td>\n",
       "      <td>Grand Ballroom A</td>\n",
       "      <td>2018-03-29 13:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>180</td>\n",
       "      <td>Trio: Async concurrency for mere mortals</td>\n",
       "      <td>Concurrent programs are super useful: think of...</td>\n",
       "      <td>Nathaniel J. Smith</td>\n",
       "      <td>2018-04-19 00:59:21.066225</td>\n",
       "      <td>2018-04-19 00:59:21.066225</td>\n",
       "      <td>Grand Ballroom C</td>\n",
       "      <td>2018-03-29 16:30:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>181</td>\n",
       "      <td>Type-checked Python in the real world</td>\n",
       "      <td>You've heard about Python type annotations, bu...</td>\n",
       "      <td>Carl Meyer</td>\n",
       "      <td>2018-04-19 00:59:21.073781</td>\n",
       "      <td>2018-04-19 00:59:21.073781</td>\n",
       "      <td>Global Center Ballroom AB</td>\n",
       "      <td>2018-03-29 13:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>186</td>\n",
       "      <td>Visual Testing with PyCharm and pytest</td>\n",
       "      <td>Know you should be doing testing but haven’t g...</td>\n",
       "      <td>Brian Okken, Paul Everitt</td>\n",
       "      <td>2018-04-19 00:59:21.093337</td>\n",
       "      <td>2018-04-19 00:59:21.093337</td>\n",
       "      <td>Grand Ballroom A</td>\n",
       "      <td>2018-03-29 17:10:00.000000</td>\n",
       "      <td>2018</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "102  103  Bayesian Non-parametric Models for Data Scienc...   \n",
       "103  104                             Behavior-Driven Python   \n",
       "105  106  Beyond Unit Tests: Taking Your Testing to the ...   \n",
       "112  113  By the Numbers: Python Community Trends in 201...   \n",
       "113  114  Clearer Code at Scale: Static Types at Zulip a...   \n",
       "126  126                    Demystifying the Patch Function   \n",
       "131  132     Elegant Solutions For Everyday Python Problems   \n",
       "134  135  Fighting the Good Fight: Python 3 in your orga...   \n",
       "138  139       How Netflix does failovers in 7 minutes flat   \n",
       "139  140                             HOWTO Write a Function   \n",
       "144  145  Inside the Cheeseshop: How Python Packaging Works   \n",
       "148  149  One weird trick to becoming a better software ...   \n",
       "151  152                                   Practical Sphinx   \n",
       "154  155                          Python 3: ten years later   \n",
       "165  166              Solve Your Problem With Sloppy Python   \n",
       "171  172                                     The AST and Me   \n",
       "177  178  There and Back Again: Disable and re-enable ga...   \n",
       "179  180           Trio: Async concurrency for mere mortals   \n",
       "180  181              Type-checked Python in the real world   \n",
       "185  186             Visual Testing with PyCharm and pytest   \n",
       "\n",
       "                                           description  \\\n",
       "102  Nowadays, there are many ways of building data...   \n",
       "103  Behavior-Driven Development (BDD) is gaining p...   \n",
       "105  You've used pytest and you've used mypy, but b...   \n",
       "112  Want to know about the latest trends in the Py...   \n",
       "113  Python now offers static types! Companies like...   \n",
       "126  One of the most challenging and important thin...   \n",
       "131  Are you an intermediate python developer looki...   \n",
       "134  Today, services built on Python 3.6.3 are wide...   \n",
       "138  During peak hours, Netflix video streams make ...   \n",
       "139  A function is a small chunk of code that does ...   \n",
       "144  Questions and confusion about the Python packa...   \n",
       "148  Those of us who have worked in software develo...   \n",
       "151  Each member of your project team uses somethin...   \n",
       "154  Looking back at Python evolutions over the las...   \n",
       "165  Stop writing crappy shell scripts—write crappy...   \n",
       "171  Get under the hood and learn about Python's be...   \n",
       "177  Python's cyclic garbage collector wonderfully ...   \n",
       "179  Concurrent programs are super useful: think of...   \n",
       "180  You've heard about Python type annotations, bu...   \n",
       "185  Know you should be doing testing but haven’t g...   \n",
       "\n",
       "                         presenters                date_created  \\\n",
       "102          Christopher Fonnesbeck  2018-04-19 00:59:20.691667   \n",
       "103                   Andrew Knight  2018-04-19 00:59:20.695767   \n",
       "105                    Hillel Wayne  2018-04-19 00:59:20.703329   \n",
       "112  Dmitry Filippov, Ewa Jodlowska  2018-04-19 00:59:20.738717   \n",
       "113                      Greg Price  2018-04-19 00:59:20.744340   \n",
       "126                      Lisa Roach  2018-04-19 00:59:20.802335   \n",
       "131                 Nina Zakharenko  2018-04-19 00:59:20.828630   \n",
       "134                     Jason Fried  2018-04-19 00:59:20.840462   \n",
       "138                Amjith Ramanujam  2018-04-19 00:59:20.860729   \n",
       "139                  Jack Diederich  2018-04-19 00:59:20.869047   \n",
       "144                   Dustin Ingram  2018-04-19 00:59:20.891093   \n",
       "148                      Esther Nam  2018-04-19 00:59:20.906538   \n",
       "151                   Carol Willing  2018-04-19 00:59:20.920561   \n",
       "154                  Victor Stinner  2018-04-19 00:59:20.940580   \n",
       "165                  Larry Hastings  2018-04-19 00:59:21.001207   \n",
       "171       Emily Morehouse-Valcarcel  2018-04-19 00:59:21.028885   \n",
       "177                        Zekun Li  2018-04-19 00:59:21.055058   \n",
       "179              Nathaniel J. Smith  2018-04-19 00:59:21.066225   \n",
       "180                      Carl Meyer  2018-04-19 00:59:21.073781   \n",
       "185       Brian Okken, Paul Everitt  2018-04-19 00:59:21.093337   \n",
       "\n",
       "                  date_modified                   location  \\\n",
       "102  2018-04-19 00:59:20.691667  Global Center Ballroom AB   \n",
       "103  2018-04-19 00:59:20.695767           Grand Ballroom A   \n",
       "105  2018-04-19 00:59:20.703329               Room 26A/B/C   \n",
       "112  2018-04-19 00:59:20.738717               Room 26A/B/C   \n",
       "113  2018-04-19 00:59:20.744340           Grand Ballroom B   \n",
       "126  2018-04-19 00:59:20.802335           Grand Ballroom B   \n",
       "131  2018-04-19 00:59:20.828630               Room 26A/B/C   \n",
       "134  2018-04-19 00:59:20.840462           Grand Ballroom B   \n",
       "138  2018-04-19 00:59:20.860729  Global Center Ballroom AB   \n",
       "139  2018-04-19 00:59:20.869047               Room 26A/B/C   \n",
       "144  2018-04-19 00:59:20.891093               Room 26A/B/C   \n",
       "148  2018-04-19 00:59:20.906538  Global Center Ballroom AB   \n",
       "151  2018-04-19 00:59:20.920561           Grand Ballroom A   \n",
       "154  2018-04-19 00:59:20.940580           Grand Ballroom B   \n",
       "165  2018-04-19 00:59:21.001207           Grand Ballroom C   \n",
       "171  2018-04-19 00:59:21.028885           Grand Ballroom B   \n",
       "177  2018-04-19 00:59:21.055058           Grand Ballroom A   \n",
       "179  2018-04-19 00:59:21.066225           Grand Ballroom C   \n",
       "180  2018-04-19 00:59:21.073781  Global Center Ballroom AB   \n",
       "185  2018-04-19 00:59:21.093337           Grand Ballroom A   \n",
       "\n",
       "                        talk_dt  year  label  \n",
       "102  2018-03-29 13:40:00.000000  2018    1.0  \n",
       "103  2018-03-29 12:10:00.000000  2018    1.0  \n",
       "105  2018-03-29 12:10:00.000000  2018    1.0  \n",
       "112  2018-03-29 13:55:00.000000  2018    1.0  \n",
       "113  2018-03-29 13:50:00.000000  2018    1.0  \n",
       "126  2018-03-29 12:10:00.000000  2018    1.0  \n",
       "131  2018-03-29 17:10:00.000000  2018    1.0  \n",
       "134  2018-03-29 16:30:00.000000  2018    1.0  \n",
       "138  2018-03-29 11:30:00.000000  2018    1.0  \n",
       "139  2018-03-29 12:10:00.000000  2018    1.0  \n",
       "144  2018-03-29 11:30:00.000000  2018    1.0  \n",
       "148  2018-03-29 12:10:00.000000  2018    1.0  \n",
       "151  2018-03-29 11:30:00.000000  2018    1.0  \n",
       "154  2018-03-29 15:15:00.000000  2018    1.0  \n",
       "165  2018-03-29 10:50:00.000000  2018    1.0  \n",
       "171  2018-03-29 15:15:00.000000  2018    1.0  \n",
       "177  2018-03-29 13:10:00.000000  2018    1.0  \n",
       "179  2018-03-29 16:30:00.000000  2018    1.0  \n",
       "180  2018-03-29 13:10:00.000000  2018    1.0  \n",
       "185  2018-03-29 17:10:00.000000  2018    1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018_talks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
